{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11d5afc8-8486-45f2-b2b1-5b1d7aa7135e",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a18fab-8c9c-47b5-815e-5aea6f853959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModel\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm, trange\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ddef26-399f-4798-a1e1-a10b59896077",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0486a4d3-6094-4699-a2df-13c841910e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALNUM_CHARSET = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789')\n",
    "\n",
    "def convert_to_tokens(indices, tokenizer, extended=False, extra_values_pos=None, strip=True):\n",
    "    if extended:\n",
    "        res = [tokenizer.convert_ids_to_tokens([idx])[0] if idx < len(tokenizer) else \n",
    "               (f\"[pos{idx-len(tokenizer)}]\" if idx < extra_values_pos else f\"[val{idx-extra_values_pos}]\") \n",
    "               for idx in indices]\n",
    "    else:\n",
    "        res = tokenizer.convert_ids_to_tokens(indices)\n",
    "    if strip:\n",
    "        res = list(map(lambda x: x[1:] if x[0] == 'Ġ' else \"#\" + x, res))\n",
    "    return res\n",
    "\n",
    "\n",
    "def top_tokens(v, k=100, tokenizer=None, only_alnum=False, only_ascii=True, with_values=False, \n",
    "               exclude_brackets=False, extended=True, extra_values=None, only_from_list=None):\n",
    "    if tokenizer is None:\n",
    "        tokenizer = my_tokenizer\n",
    "    v = deepcopy(v)\n",
    "    ignored_indices = []\n",
    "    if only_ascii:\n",
    "        ignored_indices.extend([key for val, key in tokenizer.vocab.items() if not val.strip('Ġ▁').isascii()])\n",
    "    if only_alnum: \n",
    "        ignored_indices.extend([key for val, key in tokenizer.vocab.items() if not (set(val.strip('Ġ▁[] ')) <= ALNUM_CHARSET)])\n",
    "    if only_from_list:\n",
    "        ignored_indices.extend([key for val, key in tokenizer.vocab.items() if val.strip('Ġ▁ ').lower() not in only_from_list])\n",
    "    if exclude_brackets:\n",
    "        ignored_indices = set(ignored_indices).intersection(\n",
    "            {key for val, key in tokenizer.vocab.items() if not (val.isascii() and val.isalnum())})\n",
    "        ignored_indices = list(ignored_indices)\n",
    "        \n",
    "    ignored_indices = list(set(ignored_indices))\n",
    "    v[ignored_indices] = -np.inf\n",
    "    extra_values_pos = len(v)\n",
    "    if extra_values is not None:\n",
    "        v = torch.cat([v, extra_values])\n",
    "    values, indices = torch.topk(v, k=k)\n",
    "    res = convert_to_tokens(indices, tokenizer, extended=extended, extra_values_pos=extra_values_pos)\n",
    "    if with_values:\n",
    "        res = list(zip(res, values.cpu().numpy()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e03a094-4602-47bf-89ea-0656fb4c1d5d",
   "metadata": {},
   "source": [
    "## Extract Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e82d2c-92a5-4892-afc3-b40439d6b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2-medium\")\n",
    "tokenizer = my_tokenizer = AutoTokenizer.from_pretrained(\"gpt2-medium\")\n",
    "emb = model.get_output_embeddings().weight.data.T.detach()\n",
    "\n",
    "num_layers = model.config.n_layer\n",
    "num_heads = model.config.n_head\n",
    "hidden_dim = model.config.n_embd\n",
    "head_size = hidden_dim // num_heads\n",
    "\n",
    "K = torch.cat([model.get_parameter(f\"transformer.h.{j}.mlp.c_fc.weight\").T\n",
    "                           for j in range(num_layers)]).detach()\n",
    "V = torch.cat([model.get_parameter(f\"transformer.h.{j}.mlp.c_proj.weight\")\n",
    "                           for j in range(num_layers)]).detach()\n",
    "\n",
    "W_Q, W_K, W_V = torch.cat([model.get_parameter(f\"transformer.h.{j}.attn.c_attn.weight\") \n",
    "                           for j in range(num_layers)]).detach().chunk(3, dim=-1)\n",
    "W_O = torch.cat([model.get_parameter(f\"transformer.h.{j}.attn.c_proj.weight\") \n",
    "                           for j in range(num_layers)]).detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "104fd920-f247-4827-be5a-c958dfadbe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_heads = K.reshape(num_layers, -1, hidden_dim)\n",
    "V_heads = V.reshape(num_layers, -1, hidden_dim)\n",
    "d_int = K_heads.shape[1]\n",
    "\n",
    "W_Q_heads = W_Q.reshape(num_layers, hidden_dim, num_heads, head_size).permute(0, 2, 1, 3)\n",
    "W_K_heads = W_K.reshape(num_layers, hidden_dim, num_heads, head_size).permute(0, 2, 1, 3)\n",
    "W_V_heads = W_V.reshape(num_layers, hidden_dim, num_heads, head_size).permute(0, 2, 1, 3)\n",
    "W_O_heads = W_O.reshape(num_layers, num_heads, head_size, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec5b99d-9e6c-413f-a43d-02fd39485640",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_inv = emb.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58b9e38-8ff4-41f6-8c47-8ae23f4293e6",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81b3452-6449-4397-bda7-3209c573c53a",
   "metadata": {},
   "source": [
    "#### Alternative I: No Token List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fbe8ce6-abf5-427b-b374-a43f88b06097",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada3bfc9-3d15-43ae-a21c-da0747b16ba4",
   "metadata": {},
   "source": [
    "#### Alternative II: Can Load Token List from IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bb14a77-5ac2-449b-b771-97be619cb79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fe48f8f-eb62-4bee-a45c-27ff12220825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/guydar/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9163e66061c2409aa01e39e9f981d302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb = load_dataset('imdb')['train']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae8eb81a-8525-40ef-8376-a902980c18d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens_num = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea6fd97b-1dbf-4e61-bcdb-f4f2d2c23ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 25000/25000 [00:53<00:00, 467.46it/s]\n"
     ]
    }
   ],
   "source": [
    "if max_tokens_num is None:\n",
    "    tokens_list = set()\n",
    "    for txt in tqdm(imdb):\n",
    "        tokens_list = tokens_list.union(set(tokenizer.tokenize(txt)))\n",
    "else:\n",
    "    tokens_list = Counter()\n",
    "    for txt in tqdm(imdb):\n",
    "        tokens_list.update(set(tokenizer.tokenize(txt)))\n",
    "    tokens_list = map(lambda x: x[0], tokens_list.most_common(max_tokens_num))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2944cdd-13d9-41ea-a2d8-a643ab49b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list = set([*map(lambda x: x.strip('Ġ▁').lower(), tokens_list)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd71b325-da96-47b2-99a8-6b909668b642",
   "metadata": {},
   "source": [
    "### FF Keys & Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b891ff3d-18ac-4daf-bb1b-272cc9bb00a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 907\n",
      "K           V\n",
      "----------  ----------\n",
      "hands       hand\n",
      "hand        #Hand\n",
      "#hands      Hand\n",
      "#hand       #hand\n",
      "fingers     hands\n",
      "#feet       Hands\n",
      "fingertips  fist\n",
      "claws       #hands\n",
      "paw         finger\n",
      "paws        handed\n",
      "metab       thumb\n",
      "palms       fingers\n",
      "fingert     foot\n",
      "#Hand       #handed\n",
      "fists       paw\n",
      "wrists      handing\n",
      "levers      #finger\n",
      "thumbs      #hander\n",
      "tentacles   fingertips\n",
      "feet        claw\n",
      "limb        fingert\n",
      "slider      #Foot\n",
      "#handed     Stick\n",
      "#dimension  arm\n",
      "jaws        #Accessory\n",
      "skelet      #fing\n",
      "lapt        Foot\n",
      "ankles      index\n",
      "weap        toe\n",
      "foot        #auntlet\n"
     ]
    }
   ],
   "source": [
    "i1, i2 = 23, 907\n",
    "# i1, i2 = np.random.randint(num_layers), np.random.randint(d_int)\n",
    "\n",
    "print(i1, i2)\n",
    "print(tabulate([*zip(\n",
    "    top_tokens((K_heads[i1, i2]) @ emb, k=30, only_from_list=tokens_list, only_alnum=False),\n",
    "    top_tokens((V_heads[i1, i2]) @ emb, k=30, only_from_list=tokens_list, only_alnum=False),\n",
    "    # top_tokens((-K_heads[i1, i2]) @ emb, k=200, only_from_list=tokens_list),\n",
    "    # top_tokens((-V_heads[i1, i2]) @ emb, k=200, only_from_list=tokens_list),\n",
    ")], headers=['K', 'V', '-K', '-V']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec96387-7cd5-4348-9444-6e1a10987da3",
   "metadata": {},
   "source": [
    "### Attention Weights Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "ca7323f0-7cf9-4020-bbbd-191de7fe25b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_topk(mat, min_k=500, max_k=250_000, th0=10, max_iters=10, verbose=False):\n",
    "    _get_actual_k = lambda th, th_max: torch.nonzero((mat > th) & (mat < th_max)).shape[0]\n",
    "    th_max = np.inf\n",
    "    left, right = 0, th0 \n",
    "    while True:\n",
    "        actual_k = _get_actual_k(right, th_max)\n",
    "        if verbose:\n",
    "            print(f\"one more iteration. {actual_k}\")\n",
    "        if actual_k <= max_k:\n",
    "            break\n",
    "        left, right = right, right * 2\n",
    "    if min_k <= actual_k <= max_k:\n",
    "        th = right\n",
    "    else:\n",
    "        for _ in range(max_iters):\n",
    "            mid = (left + right) / 2\n",
    "            actual_k = _get_actual_k(mid, th_max)\n",
    "            if verbose:\n",
    "                print(f\"one more iteration. {actual_k}\")\n",
    "            if min_k <= actual_k <= max_k:\n",
    "                break\n",
    "            if actual_k > max_k:\n",
    "                left = mid\n",
    "            else:\n",
    "                right = mid\n",
    "        th = mid\n",
    "    return torch.nonzero((mat > th) & (mat < th_max)).tolist()\n",
    "\n",
    "def get_top_entries(tmp, all_high_pos, only_ascii=False, only_alnum=False, exclude_same=False, exclude_fuzzy=False, tokens_list=None):\n",
    "    remaining_pos = all_high_pos\n",
    "    if only_ascii:\n",
    "        remaining_pos = [*filter(\n",
    "            lambda x: (tokenizer.decode(x[0]).strip('Ġ▁').isascii() and tokenizer.decode(x[1]).strip('Ġ▁').isascii()), \n",
    "            remaining_pos)]\n",
    "    if only_alnum:\n",
    "        remaining_pos = [*filter(\n",
    "            lambda x: (tokenizer.decode(x[0]).strip('Ġ▁ ').isalnum() and tokenizer.decode(x[1]).strip('Ġ▁ ').isalnum()), \n",
    "            remaining_pos)]\n",
    "    if exclude_same:\n",
    "        remaining_pos = [*filter(\n",
    "            lambda x: tokenizer.decode(x[0]).lower().strip() != tokenizer.decode(x[1]).lower().strip(), \n",
    "            remaining_pos)]\n",
    "    if exclude_fuzzy:\n",
    "        remaining_pos = [*filter(\n",
    "            lambda x: not _fuzzy_eq(tokenizer.decode(x[0]).lower().strip(), tokenizer.decode(x[1]).lower().strip()), \n",
    "            remaining_pos)]\n",
    "    if tokens_list:\n",
    "        remaining_pos = [*filter(\n",
    "            lambda x: ((tokenizer.decode(x[0]).strip('Ġ▁').lower().strip() in tokens_list) and \n",
    "                       (tokenizer.decode(x[1]).strip('Ġ▁').lower().strip() in tokens_list)), \n",
    "            remaining_pos)]\n",
    "\n",
    "    pos_val = tmp[[*zip(*remaining_pos)]]\n",
    "    good_cells = [*map(lambda x: (tokenizer.decode(x[0]), tokenizer.decode(x[1])), remaining_pos)]\n",
    "    good_tokens = list(map(lambda x: Counter(x).most_common(), zip(*good_cells)))\n",
    "    remaining_pos_best = np.array(remaining_pos)[torch.argsort(pos_val if reverse_list else -pos_val)[:50]]\n",
    "    good_cells_best = [*map(lambda x: (tokenizer.decode(x[0]), tokenizer.decode(x[1])), remaining_pos_best)]\n",
    "    # good_cells[:100]\n",
    "    # list(zip(good_tokens[0], good_tokens[1]))\n",
    "    return good_cells_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbd4e4a-a69b-4d58-a371-426b9073ff81",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### $W_{VO}$ Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79156807-54af-4fe8-b170-29dc0856d686",
   "metadata": {},
   "source": [
    "Choose **layer** and **head** here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f0d00edd-fdca-40d0-807f-e4bf3d7611e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 9)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1, i2 = np.random.randint(num_layers), np.random.randint(num_heads)\n",
    "i1, i2 = 24, 9\n",
    "i1, i2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "2743e277-74f7-41a6-a479-5bd65840d2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_V_tmp, W_O_tmp = W_V_heads[i1, i2, :], W_O_heads[i1, i2]\n",
    "tmp = (emb_inv @ (W_V_tmp @ W_O_tmp) @ emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "0ede26ee-3b82-4446-8b6d-2300e7bdcc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one more iteration. 11496\n"
     ]
    }
   ],
   "source": [
    "all_high_pos = approx_topk(tmp, th0=1, verbose=True) # torch.nonzero((tmp > th) & (tmp < th_max)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "3207aed9-f99e-4109-9160-2d62f31e8b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_same = False\n",
    "reverse_list = False\n",
    "only_ascii = True\n",
    "only_alnum = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "0fab412a-3f2e-4e0c-b11e-c462b17b6191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' interviewer', ' interviewer'),\n",
       " (' lectures', ' lectures'),\n",
       " (' lecture', ' lecture'),\n",
       " ('Interview', ' interview'),\n",
       " (' interview', ' interview'),\n",
       " (' interviewer', ' interview'),\n",
       " (' interviewing', ' interviewing'),\n",
       " (' magazine', ' magazine'),\n",
       " (' Reviews', ' Reviews'),\n",
       " (' reviewer', ' reviewer'),\n",
       " (' reviewers', ' reviewers'),\n",
       " (' lecture', ' lectures'),\n",
       " (' testers', ' testers'),\n",
       " (' editors', ' editors'),\n",
       " (' interview', ' interviewer'),\n",
       " ('Interview', ' Interview'),\n",
       " ('Interview', ' interviewer'),\n",
       " ('Interview', 'Interview'),\n",
       " (' lectures', ' lecture'),\n",
       " (' interviewer', ' interviewing'),\n",
       " (' journal', ' journal'),\n",
       " (' interviewing', ' interviewer'),\n",
       " (' blogs', ' blogs'),\n",
       " (' editorial', ' editorial'),\n",
       " (' tests', ' tests'),\n",
       " (' presentations', ' presentations'),\n",
       " (' Editorial', ' Editorial'),\n",
       " (' Interview', ' interview'),\n",
       " (' reviewers', ' reviewer'),\n",
       " ('Interview', ' interviews'),\n",
       " (' interviewing', ' interview'),\n",
       " (' Interview', ' interviewer'),\n",
       " (' interview', ' interviews'),\n",
       " (' Interview', ' Interview'),\n",
       " ('Interview', ' interviewing'),\n",
       " (' interviewer', 'Interview'),\n",
       " (' testifying', ' testifying'),\n",
       " (' reviewer', ' reviewers'),\n",
       " (' blogging', ' blogging'),\n",
       " (' broadcast', ' broadcast'),\n",
       " (' interviewer', ' Interview'),\n",
       " (' magazines', ' magazine'),\n",
       " (' Editorial', ' editorial'),\n",
       " (' interviews', ' interview'),\n",
       " (' interview', ' interviewing'),\n",
       " (' interview', ' Interview'),\n",
       " (' interviews', ' interviews'),\n",
       " ('tests', ' tests'),\n",
       " (' interviewing', ' interviews'),\n",
       " (' interview', 'Interview')]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_entries(tmp, all_high_pos, only_ascii=only_ascii, only_alnum=only_alnum, \n",
    "                exclude_same=exclude_same, tokens_list=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49638ac2-455c-4441-aa67-4fde61c9ea83",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### $W_{QK}$ Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbfc882-3bf7-46e5-8e6a-f6a245ceb7bf",
   "metadata": {},
   "source": [
    "Choose **layer** and **head** here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "c43e9c99-f9bf-4eae-b215-289a7f630ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 13)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i1, i2 = np.random.randint(num_layers), np.random.randint(num_heads)\n",
    "i1, i2 = 20, 13\n",
    "i1, i2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "e74cb0c2-c39f-42ce-a87c-91125207d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Q_tmp, W_K_tmp = W_Q_heads[i1, i2, :], W_K_heads[i1, i2, :]\n",
    "tmp2 = (emb_inv @ (W_Q_tmp @ W_K_tmp.T) @ emb_inv.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "26a461fb-bcbc-477a-be76-20f5b52f329d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one more iteration. 265\n",
      "one more iteration. 103159\n"
     ]
    }
   ],
   "source": [
    "all_high_pos = approx_topk(tmp2, th0=1, verbose=True) # torch.nonzero((tmp2 > th2) & (tmp2 < th_max2)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "16706487-23da-4e39-9799-641528d2e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_same = False\n",
    "reverse_list = False\n",
    "only_ascii = True\n",
    "only_alnum = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "4e402a1a-8481-4481-9bad-a10f70542b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' outdoors', ' outdoors'),\n",
       " (' outdoor', ' outdoors'),\n",
       " (' Gre', 'burg'),\n",
       " (' healing', ' healing'),\n",
       " (' indoor', ' outdoors'),\n",
       " (' Hemp', 'burg'),\n",
       " (' Ticket', ' Ticket'),\n",
       " (' accommodations', ' accommodations'),\n",
       " ('eco', 'aco'),\n",
       " ('prem', 'otti'),\n",
       " (' Candy', 'cott'),\n",
       " (' decorative', ' ornament'),\n",
       " ('yan', 'ava'),\n",
       " (' deadlines', ' schedule'),\n",
       " (' Lor', 'ian'),\n",
       " (' architectural', ' ornament'),\n",
       " (' Ratings', ' Ratings'),\n",
       " (' Bod', 'za'),\n",
       " (' exotic', ' exotic'),\n",
       " (' food', ' baths'),\n",
       " (' Marketplace', ' Marketplace'),\n",
       " (' heal', ' healing'),\n",
       " (' Ex', 'ilus'),\n",
       " (' indoors', ' outdoors'),\n",
       " (' therm', ' therm'),\n",
       " (' bleach', ' coated'),\n",
       " (' Sod', 'opol'),\n",
       " (' District', ' Metropolitan'),\n",
       " (' Anonymous', ' Rebell'),\n",
       " (' Corn', 'burg'),\n",
       " (' indoor', ' indoors'),\n",
       " (' R', 'vale'),\n",
       " ('rom', 'otti'),\n",
       " (' ratings', ' Ratings'),\n",
       " (' attendance', ' attendance'),\n",
       " (' destinations', ' destinations'),\n",
       " (' VIDEOS', ' VIDEOS'),\n",
       " ('yan', 'opol'),\n",
       " (' Suffolk', 'ville'),\n",
       " (' retali', ' against'),\n",
       " ('mos', 'oli'),\n",
       " (' pacing', ' pacing'),\n",
       " (' Spectrum', ' QC'),\n",
       " (' Il', 'ian'),\n",
       " (' archived', ' archived'),\n",
       " (' Pledge', ' Pledge'),\n",
       " ('alg', 'otti'),\n",
       " (' Freedom', 'USA'),\n",
       " ('anto', 'ero'),\n",
       " (' decorative', ' decoration')]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_entries(tmp2, all_high_pos, only_ascii=only_ascii, only_alnum=only_alnum, exclude_same=exclude_same, \n",
    "                tokens_list=tokens_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e6b973-a8c8-4775-aa69-fa1bac08c450",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c30e8596-b8a1-4b53-935c-24318aca7fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "i1, i2 = 6, 2152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99271972-75c1-4cc2-b0be-c5f0895558fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fb14d53-dc5d-47aa-8609-3633843e1d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calc_df(vector, k, coef, normalized, tokenizer):\n",
    "    mat = emb\n",
    "    if normalized:\n",
    "        mat = F.normalize(mat, dim=-1)\n",
    "    dot = vector @ mat\n",
    "    sol = torch.topk(dot * coef, k=k).indices # np.argsort(dot * coef)[-k:]\n",
    "    pattern = mat[:, sol].T\n",
    "    scores = coef * dot[sol]\n",
    "    # labels = tokenizer.batch_decode(sol)\n",
    "    labels = convert_to_tokens(sol, tokenizer=tokenizer)\n",
    "    X_embedded = TSNE(n_components=3,\n",
    "                  learning_rate=10,\n",
    "                   init='pca',\n",
    "                   perplexity=3).fit_transform(pattern)\n",
    "\n",
    "    df = pd.DataFrame(dict(x=X_embedded.T[0], y=X_embedded.T[1], z=X_embedded.T[2], label=labels, score=scores))\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_embedding_space(vector, is_3d=False, add_text=False, k=100, coef=1, normalized=False, tokenizer=None):\n",
    "    df = _calc_df(vector, k=k, coef=coef, normalized=normalized, tokenizer=tokenizer)\n",
    "    kwargs = {}\n",
    "    scatter_fn = px.scatter\n",
    "    if add_text:\n",
    "        kwargs.update({'text': 'label'})\n",
    "    if is_3d:\n",
    "        scatter_fn = px.scatter_3d\n",
    "        kwargs.update({'z': 'z'})\n",
    "    fig = scatter_fn(\n",
    "        data_frame=df, \n",
    "        x='x', \n",
    "        y='y',\n",
    "        custom_data=[\"label\", \"score\"],\n",
    "        color=\"score\", size_max=1, **kwargs)\n",
    "\n",
    "    fig.update_traces(\n",
    "        hovertemplate=\"<br>\".join([\n",
    "            \"ColX: %{x}\",\n",
    "            \"ColY: %{y}\",\n",
    "            \"label: %{customdata[0]}\",\n",
    "            \"score: %{customdata[1]}\"\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    if add_text:\n",
    "        fig.update_traces(textposition='middle right')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80575a88-3633-4a10-9e0e-9c1b41c65c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embedding_space(K_heads[i1][i2], tokenizer=tokenizer, normalized=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
