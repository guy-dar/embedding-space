{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c4c816e-f4ca-43ba-8000-c93942620147",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "0dd22ca7-dbdd-4855-83ac-405efbf1e408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from copy import deepcopy\n",
    "from transformers import (AutoModelForMaskedLM, AutoModelForCausalLM, AutoTokenizer, \n",
    "                          AutoModelForSequenceClassification, TrainingArguments, Trainer)\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from tensorflow.keras.models import load_model\n",
    "from datasets import load_dataset, load_metric\n",
    "import os\n",
    "from utils import top_tokens\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb2ad759-4d6f-4381-9148-e038e0d48f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_output_emb(model):\n",
    "#     transform = model.cls.predictions.transform.dense.weight.T\n",
    "#     orig_emb = model.get_output_embeddings().weight.T\n",
    "#     return (transform @ orig_emb).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de110f35-828b-40b4-8bfe-89973eeaa490",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 12\n",
    "hidden_dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07fdd79f-7d70-4548-8b9c-909cc86d81f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2') # ('bert-base-uncased') # get_multiberts_tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4d2819-e575-4f98-83af-1cd016b88bce",
   "metadata": {},
   "source": [
    "### Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ba62929-5478-467a-976d-2b04ca1ccb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt2', 'gpt2-medium']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_paths = ['gpt2', 'gpt2-medium'] # [\"bert-base-uncased\", f\"multiberts/models/seed_0\"] # [f\"multiberts/models/seed_{i}\" for i in range(2)]\n",
    "print(model_paths)\n",
    "\n",
    "model1_tmp = AutoModelForCausalLM.from_pretrained(model_paths[0]) # need to get the output emb matrix from model1\n",
    "model2 = AutoModelForCausalLM.from_pretrained(model_paths[1])\n",
    "emb1, emb2 = map(lambda model: model.get_output_embeddings().weight.T.cpu().detach(), [model1_tmp, model2])\n",
    "del model1_tmp # now we no longer need model1_tmp\n",
    "model1 = AutoModelForSequenceClassification.from_pretrained(model_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82200f0b-6d47-43f5-a9ea-3ef63f7a3327",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove pooler for simplicity - leave only classifier \n",
    "# model1.bert.pooler.dense = nn.Identity()\n",
    "# model1.bert.pooler.activation = nn.Identity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddac8634-3bad-4a8a-9344-a90d6f1f94a2",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f0f339-4a8e-4780-be94-40a3ffd9cef2",
   "metadata": {},
   "source": [
    "### Sentiment Analysis Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "601e4a50-cf00-4245-a62e-421113db425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze = 9 # number of layers to freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48bcbc0b-3ee5-4494-9e92-1a65504e7870",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6334e3f-07d6-4425-bfaa-292804068c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1997c9a5-6331-441f-b02b-1f05e18a80db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unfrozen parameters:\n",
      "transformer.h.9.ln_1.weight\n",
      "transformer.h.9.ln_1.bias\n",
      "transformer.h.9.attn.c_attn.weight\n",
      "transformer.h.9.attn.c_attn.bias\n",
      "transformer.h.9.attn.c_proj.weight\n",
      "transformer.h.9.attn.c_proj.bias\n",
      "transformer.h.9.ln_2.weight\n",
      "transformer.h.9.ln_2.bias\n",
      "transformer.h.9.mlp.c_fc.weight\n",
      "transformer.h.9.mlp.c_fc.bias\n",
      "transformer.h.9.mlp.c_proj.weight\n",
      "transformer.h.9.mlp.c_proj.bias\n",
      "transformer.h.10.ln_1.weight\n",
      "transformer.h.10.ln_1.bias\n",
      "transformer.h.10.attn.c_attn.weight\n",
      "transformer.h.10.attn.c_attn.bias\n",
      "transformer.h.10.attn.c_proj.weight\n",
      "transformer.h.10.attn.c_proj.bias\n",
      "transformer.h.10.ln_2.weight\n",
      "transformer.h.10.ln_2.bias\n",
      "transformer.h.10.mlp.c_fc.weight\n",
      "transformer.h.10.mlp.c_fc.bias\n",
      "transformer.h.10.mlp.c_proj.weight\n",
      "transformer.h.10.mlp.c_proj.bias\n",
      "transformer.h.11.ln_1.weight\n",
      "transformer.h.11.ln_1.bias\n",
      "transformer.h.11.attn.c_attn.weight\n",
      "transformer.h.11.attn.c_attn.bias\n",
      "transformer.h.11.attn.c_proj.weight\n",
      "transformer.h.11.attn.c_proj.bias\n",
      "transformer.h.11.ln_2.weight\n",
      "transformer.h.11.ln_2.bias\n",
      "transformer.h.11.mlp.c_fc.weight\n",
      "transformer.h.11.mlp.c_fc.bias\n",
      "transformer.h.11.mlp.c_proj.weight\n",
      "transformer.h.11.mlp.c_proj.bias\n",
      "score.weight\n"
     ]
    }
   ],
   "source": [
    "print(\"unfrozen parameters:\")\n",
    "for n, p in model.named_parameters():\n",
    "    p.requires_grad = False\n",
    "    if len(n.split('transformer.h.')) == 2:# and n.endswith('.weight'): # '.encoder.layer.'\n",
    "        if int(n.split('transformer.h.')[1].split('.')[0]) >= freeze:\n",
    "            p.requires_grad = True\n",
    "            print(n)\n",
    "    if 'score' in n: # n.endswith('.classifier.weight'): # 'classifier'\n",
    "        p.requires_grad = True\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe41f0eb-e58f-45f8-9cf3-f4aff4e6c100",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11a17d09-8034-4df8-b1a0-62ff7814598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_imdb(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46bcd56a-e0f0-4bd4-abb7-7f43dde6e29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/guydar/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397c712514754e9a90ec8780e4c53af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "accf705b9dee4f27a743745abc5e612d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01291f88b49426f98530253708d752a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2bb04fdcb6a49bfbf453fb6c9b4db05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb = load_dataset('imdb')\n",
    "imdb = imdb.map(tokenize_imdb, batched=False)\n",
    "imdb_train, imdb_val = imdb['train'].shuffle(seed=42).select(range(1000)), imdb['test'].shuffle(seed=42).select(range(500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ca5ca0-367c-4a78-90cf-fe550e4dd346",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3460654a-3f6b-4469-87ab-123ab78abccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric('accuracy')\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3afd2645-9df9-4185-9219-619b6623b8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66a63fc7-d14c-484b-b4cf-e7223fd23997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "train_args = TrainingArguments(learning_rate=1e-5, report_to=None, output_dir='trainer_output', \n",
    "                               per_device_eval_batch_size=1, per_device_train_batch_size=1, \n",
    "                               save_steps=False, evaluation_strategy='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38f57c62-7d19-40b0-bcd0-2a869ae0d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args._n_gpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9a30474-c98a-46ff-9925-851652170702",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "432e8261-d5a1-468e-a62e-c1a79a5324be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/mnt/netapp7/dar/miniconda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 02:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.816300</td>\n",
       "      <td>1.502365</td>\n",
       "      <td>0.654000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.874200</td>\n",
       "      <td>1.462001</td>\n",
       "      <td>0.748000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.783800</td>\n",
       "      <td>1.374542</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: text. If text are not expected by `GPT2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3000, training_loss=0.8662202860514323, metrics={'train_runtime': 129.1166, 'train_samples_per_second': 23.235, 'train_steps_per_second': 23.235, 'total_flos': 436270138933248.0, 'train_loss': 0.8662202860514323, 'epoch': 3.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(model, args=train_args, train_dataset=imdb_train, eval_dataset=imdb_val, \n",
    "                  compute_metrics=compute_metrics)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6685ad43-e590-4e53-b776-cce678426ca8",
   "metadata": {},
   "source": [
    "### Visualize Finetuning Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7cc0792-d95a-4418-a58d-5999a2045af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_classifier = model.score.weight.detach().cpu() - old_model.score.weight.detach()\n",
    "# diff_classifier = model.classifier.weight.detach().cpu() - old_model.classifier.weight.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e949f1f-b149-4ee3-b521-d7f262aa563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_vector = diff_classifier[0, :]\n",
    "pos_vector = diff_classifier[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "557b80ff-3285-4ba3-9397-0ac00d46ade9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enjoy',\n",
       " 'Highly',\n",
       " 'love',\n",
       " 'Love',\n",
       " 'Thank',\n",
       " 'Enjoy',\n",
       " 'enjoyed',\n",
       " 'Together',\n",
       " 'Definitely',\n",
       " 'loved',\n",
       " 'Proud',\n",
       " 'LOVE',\n",
       " 'loving',\n",
       " 'lovers',\n",
       " 'Preview',\n",
       " '#Love',\n",
       " 'Loving',\n",
       " 'proud',\n",
       " '#love',\n",
       " 'cherish',\n",
       " 'Rated',\n",
       " 'loves',\n",
       " 'Thanks',\n",
       " '#<|endoftext|>',\n",
       " 'Beaut',\n",
       " 'admired',\n",
       " 'Favorite',\n",
       " 'timeless',\n",
       " ':)',\n",
       " 'adore',\n",
       " 'Watching',\n",
       " 'immensely',\n",
       " 'Both',\n",
       " '#Together',\n",
       " 'It',\n",
       " 'Born',\n",
       " 'beautifully',\n",
       " 'powerfully',\n",
       " 'complementary',\n",
       " 'admiration',\n",
       " 'pleasure',\n",
       " 'wonderfully',\n",
       " 'xx',\n",
       " 'Recommended',\n",
       " 'Inspired',\n",
       " 'great',\n",
       " 'favorite',\n",
       " '#ilee',\n",
       " 'wonderful',\n",
       " 'enjoys',\n",
       " 'Beautiful',\n",
       " 'milestone',\n",
       " 'celebrate',\n",
       " 'Happy',\n",
       " 'watch',\n",
       " 'appreciated',\n",
       " 'terrific',\n",
       " 'favorites',\n",
       " 'thank',\n",
       " 'kindred',\n",
       " '#Favorite',\n",
       " 'cheers',\n",
       " 'unforgettable',\n",
       " '#beaut',\n",
       " 'Also',\n",
       " 'Celebr',\n",
       " 'romance',\n",
       " 'enormously',\n",
       " 'Wonderful',\n",
       " '#ilyn',\n",
       " 'premie',\n",
       " 'Bless',\n",
       " '#Reviewer',\n",
       " 'Great',\n",
       " 'strong',\n",
       " '#Thank',\n",
       " 'warm',\n",
       " 'husband',\n",
       " 'celebrated',\n",
       " 'tribute',\n",
       " 'enjoying',\n",
       " 'Written',\n",
       " 'nurture',\n",
       " 'insepar',\n",
       " 'Featuring',\n",
       " 'Juliet',\n",
       " 'lovely',\n",
       " 'Best',\n",
       " '#Beaut',\n",
       " 'Check',\n",
       " 'cherished',\n",
       " 'murd',\n",
       " 'Along',\n",
       " 'starred',\n",
       " 'One',\n",
       " 'affection',\n",
       " 'versatile',\n",
       " 'thrilling',\n",
       " 'fabulous',\n",
       " 'beautiful']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tokens(pos_vector @ emb1, k=100, only_ascii=True, tokenizer=tokenizer)\n",
    "# top_tokens(pos_vector @ emb1, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01dbeb02-b75c-431b-8169-8227ec8cd764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Block(\n",
       "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (attn): GPT2Attention(\n",
       "    (c_attn): Conv1D()\n",
       "    (c_proj): Conv1D()\n",
       "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (mlp): GPT2MLP(\n",
       "    (c_fc): Conv1D()\n",
       "    (c_proj): Conv1D()\n",
       "    (act): NewGELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.h[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4f1f26d4-c57f-44a7-976c-c02c8535afbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = 11 # this is the layer we visualize\n",
    "diff_K = (model.transformer.h[i1].mlp.c_fc.weight.cpu() - old_model.transformer.h[i1].mlp.c_fc.weight).T\n",
    "diff_V = (model.transformer.h[i1].mlp.c_proj.weight.cpu() - old_model.transformer.h[i1].mlp.c_proj.weight)\n",
    "diff_WQ, diff_WK, diff_WV = ((model.transformer.h[i1].attn.c_attn.weight.cpu() - old_model.transformer.h[i1].attn.c_attn.weight)\n",
    "                             .T.chunk(3))\n",
    "diff_WO = (model.transformer.h[i1].attn.c_proj.weight.cpu() - old_model.transformer.h[i1].attn.c_proj.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "8977bab0-6c83-4ac3-a842-d6d7c93e3c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_param = diff_WV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "2c76f6cb-8acd-4753-b0d9-50b59748cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "i2 = np.random.randint(diff_param.shape[0]) # index of vector in the parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "e8840f5a-3b4e-4b6a-8cc1-06752ec66c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff         -diff\n",
      "-----------  -------------\n",
      "Nope         Selected\n",
      ":(           jointly\n",
      "FUCK         pioneering\n",
      "#Fuck        #emaker\n",
      "#Seriously   Luxem\n",
      "Fuck         #verning\n",
      "#Anyway      #ezvous\n",
      "goddamn      complementary\n",
      "shitty       embod\n",
      "crap         bilingual\n",
      "lol          pioneer\n",
      "#Damn        integ\n",
      "Shit         Joint\n",
      "fucking      anticip\n",
      "#Honestly    underway\n",
      "Worse        #ilateral\n",
      "Godd         embodied\n",
      "fuck         #iscover\n",
      "Sorry        powerfully\n",
      "Stupid       unmatched\n",
      "Worst        #erning\n",
      "anyways      Emerson\n",
      "idiots       delighted\n",
      "#Sorry       collabor\n",
      "Seriously    lumin\n",
      "stupid       distinguished\n",
      "lame         embraces\n",
      "#lol         embody\n",
      "#Instead     inaug\n",
      "godd         distinctive\n",
      "shit         complement\n",
      "Damn         liberated\n",
      "dunno        insepar\n",
      "crappy       congen\n",
      "#shit        #ultane\n",
      "bullshit     renowned\n",
      "pathetic     #tains\n",
      "Didn         possesses\n",
      "Okay         #estead\n",
      "Anyway       embodies\n",
      "idiot        #ographed\n",
      "OMG          harmon\n",
      "damn         emerging\n",
      "Honestly     #ciplinary\n",
      "Huh          possessing\n",
      "#Okay        #ilingual\n",
      "#@#          admired\n",
      "#Alright     #mate\n",
      "#Unless      poised\n",
      "sucks        reperto\n",
      "#fuck        Lauder\n",
      "didnt        #allel\n",
      "#Maybe       capt\n",
      "pointless    accompany\n",
      "asshole      capturing\n",
      "worthless    nurt\n",
      "retarded     reciprocal\n",
      "Oops         photograph\n",
      "LOL          accompanies\n",
      "Wrong        unparalleled\n",
      "piss         #ynamic\n",
      "freaking     envelop\n",
      "#Either      #semble\n",
      "#worst       evolves\n",
      "haha         pioneers\n",
      "#Oh          celebrated\n",
      "fuckin       interpreter\n",
      "Unless       #ouver\n",
      "#HAHA        synthes\n",
      "#HAHAHAHA    enriched\n",
      "#sorry       #igen\n",
      "#Wr          Born\n",
      "stupidity    embracing\n",
      "worst        penet\n",
      "boring       extracts\n",
      "Maybe        milestone\n",
      "#Thankfully  #lav\n",
      "suck         #accompan\n",
      "#Too         ensemble\n",
      "THEN         collaboration\n",
      "Instead      exponent\n",
      "#Jesus       pioneered\n",
      "#AAAAAAAA    prepares\n",
      "whine        delight\n",
      "blah         recogn\n",
      "#yeah        incorporating\n",
      "WHY          virt\n",
      "#Huh         landmark\n",
      "Wouldn       influenced\n",
      "Guess        photographed\n",
      "#Wait        Berger\n",
      "#didn        Carnegie\n",
      "#ooo         aboard\n",
      "Thankfully   #inguished\n",
      "Nah          rhythms\n",
      "useless      collaborating\n",
      "#Yeah        assemb\n",
      "worse        dynam\n",
      "fucked       prosper\n",
      "#THIS        master\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(zip(*[top_tokens(diff_param[i2].detach() @ emb1, k=100, only_ascii=True, tokenizer=tokenizer),\n",
    "                top_tokens(-diff_param[i2].detach() @ emb1, k=100, only_ascii=True, tokenizer=tokenizer)]), \n",
    "               headers=[\"diff\", \"-diff\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c43a2fb-5edb-4ed1-8d94-a54213998789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271fa53f-ff22-43e6-a471-945629f46082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
