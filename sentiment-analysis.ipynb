{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c4c816e-f4ca-43ba-8000-c93942620147",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dd22ca7-dbdd-4855-83ac-405efbf1e408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from copy import deepcopy\n",
    "from transformers import (AutoModelForMaskedLM, AutoModelForCausalLM, AutoTokenizer, AutoModelForTokenClassification,\n",
    "                          AutoModelForSequenceClassification, TrainingArguments, Trainer)\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from tensorflow.keras.models import load_model\n",
    "from datasets import load_dataset, load_metric\n",
    "import os\n",
    "from utils import top_tokens\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07fdd79f-7d70-4548-8b9c-909cc86d81f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2') # ('bert-base-uncased') # get_multiberts_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f14b9d71-1578-402e-bb0e-e343f0cbd78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gpt2AvgClassifier(nn.Module):\n",
    "    def __init__(self, name, freeze=None, num_labels=2):\n",
    "        super().__init__()\n",
    "        self.model = AutoModelForTokenClassification.from_pretrained(name, num_labels=num_labels)\n",
    "        self.model.transformer.ln_f = nn.Identity(self.model.config.n_ctx)\n",
    "        if freeze is not None:\n",
    "            for n, p in self.named_parameters():\n",
    "                p.requires_grad = False\n",
    "                if len(n.split('.transformer.h.')) == 2 and n.endswith('.weight'):\n",
    "                    if int(n.split('.transformer.h.')[1].split('.')[0]) >= freeze:\n",
    "                        p.requires_grad = True\n",
    "                        print(n)\n",
    "                if n.endswith('.classifier.weight'):\n",
    "                    p.requires_grad = True\n",
    "                    print(n)\n",
    "                    \n",
    "    def forward(self, input_ids, labels, inputs_embeds=None):\n",
    "        res = self.model(input_ids=input_ids, inputs_embeds=inputs_embeds)\n",
    "        res.logits = res.logits.mean(dim=-2)\n",
    "        res['loss'] = F.cross_entropy(res.logits.view(-1, res.logits.shape[-1]), labels.view(-1))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4d2819-e575-4f98-83af-1cd016b88bce",
   "metadata": {},
   "source": [
    "### Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "601e4a50-cf00-4245-a62e-421113db425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze = 9 # number of layers to freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03ace372-e479-4caa-bcf3-68043ebeb0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt2', 'gpt2-medium']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForTokenClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.4.attn.masked_bias', 'h.6.attn.masked_bias', 'classifier.bias', 'h.5.attn.masked_bias', 'h.2.attn.masked_bias', 'h.8.attn.masked_bias', 'h.11.attn.masked_bias', 'h.7.attn.masked_bias', 'h.0.attn.masked_bias', 'classifier.weight', 'h.3.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.1.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.transformer.h.9.ln_1.weight\n",
      "model.transformer.h.9.attn.c_attn.weight\n",
      "model.transformer.h.9.attn.c_proj.weight\n",
      "model.transformer.h.9.ln_2.weight\n",
      "model.transformer.h.9.mlp.c_fc.weight\n",
      "model.transformer.h.9.mlp.c_proj.weight\n",
      "model.transformer.h.10.ln_1.weight\n",
      "model.transformer.h.10.attn.c_attn.weight\n",
      "model.transformer.h.10.attn.c_proj.weight\n",
      "model.transformer.h.10.ln_2.weight\n",
      "model.transformer.h.10.mlp.c_fc.weight\n",
      "model.transformer.h.10.mlp.c_proj.weight\n",
      "model.transformer.h.11.ln_1.weight\n",
      "model.transformer.h.11.attn.c_attn.weight\n",
      "model.transformer.h.11.attn.c_proj.weight\n",
      "model.transformer.h.11.ln_2.weight\n",
      "model.transformer.h.11.mlp.c_fc.weight\n",
      "model.transformer.h.11.mlp.c_proj.weight\n",
      "model.classifier.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_paths = ['gpt2', 'gpt2-medium'] \n",
    "\n",
    "print(model_paths)\n",
    "\n",
    "model1 = Gpt2AvgClassifier(model_paths[0], freeze=freeze) # AutoModelForSequenceClassification.from_pretrained(model_paths[0])\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(model_paths[1])\n",
    "# we can use input embedding as the embedding matrices are tied\n",
    "emb1 = model1.model.get_input_embeddings().weight.T.cpu().detach() \n",
    "emb2 = model2.get_input_embeddings().weight.T.cpu().detach() \n",
    "num_layers1, hidden_dim1 = (model1.model.config.n_layer, model1.model.config.n_embd)\n",
    "num_layers2, hidden_dim2 = (model2.config.n_layer, model2.config.n_embd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f0f339-4a8e-4780-be94-40a3ffd9cef2",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48bcbc0b-3ee5-4494-9e92-1a65504e7870",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe41f0eb-e58f-45f8-9cf3-f4aff4e6c100",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11a17d09-8034-4df8-b1a0-62ff7814598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_imdb(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46bcd56a-e0f0-4bd4-abb7-7f43dde6e29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/guydar/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be9861acc9c94a6c9bc9c1062336e129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/guydar/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-3524c89eaed1ab3e.arrow\n",
      "Loading cached processed dataset at /home/guydar/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-bd746f6e0438ac54.arrow\n",
      "Loading cached processed dataset at /home/guydar/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-fcdd099119f0e220.arrow\n",
      "Loading cached shuffled indices for dataset at /home/guydar/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a/cache-0f38f07d8eec9b87.arrow\n"
     ]
    }
   ],
   "source": [
    "imdb = load_dataset('imdb')\n",
    "imdb = imdb.map(tokenize_imdb, batched=False)\n",
    "imdb_train, imdb_val = imdb['train'].shuffle().select(range(3000)), imdb['test'].shuffle().select(range(500))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ca5ca0-367c-4a78-90cf-fe550e4dd346",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3460654a-3f6b-4469-87ab-123ab78abccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric('accuracy')\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3afd2645-9df9-4185-9219-619b6623b8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66a63fc7-d14c-484b-b4cf-e7223fd23997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "train_args = TrainingArguments(learning_rate=1e-5, report_to=None, output_dir='trainer_output', \n",
    "                               per_device_eval_batch_size=1, per_device_train_batch_size=1, \n",
    "                               save_steps=False, evaluation_strategy='epoch', num_train_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38f57c62-7d19-40b0-bcd0-2a869ae0d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args._n_gpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9a30474-c98a-46ff-9925-851652170702",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "432e8261-d5a1-468e-a62e-c1a79a5324be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `Gpt2AvgClassifier.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `Gpt2AvgClassifier.forward`,  you can safely ignore this message.\n",
      "/mnt/netapp7/dar/miniconda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 01:33, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.636800</td>\n",
       "      <td>0.950526</td>\n",
       "      <td>0.832000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `Gpt2AvgClassifier.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `Gpt2AvgClassifier.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3000, training_loss=0.8896415710449219, metrics={'train_runtime': 93.5903, 'train_samples_per_second': 32.055, 'train_steps_per_second': 32.055, 'total_flos': 0.0, 'train_loss': 0.8896415710449219, 'epoch': 1.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(model1, args=train_args, train_dataset=imdb_train, eval_dataset=imdb_val, \n",
    "                  compute_metrics=compute_metrics)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6685ad43-e590-4e53-b776-cce678426ca8",
   "metadata": {},
   "source": [
    "### Visualize Finetuning Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7cc0792-d95a-4418-a58d-5999a2045af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_classifier = (model.model.classifier.weight.cpu() - old_model.model.classifier.weight.cpu()).detach()\n",
    "# diff_classifier = model.score.weight.detach().cpu() - old_model.score.weight.detach()\n",
    "# diff_classifier = model.classifier.weight.detach().cpu() - old_model.classifier.weight.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e949f1f-b149-4ee3-b521-d7f262aa563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_vector = diff_classifier[0, :]\n",
    "pos_vector = diff_classifier[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "557b80ff-3285-4ba3-9397-0ac00d46ade9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE    NEGATIVE\n",
      "----------  ------------\n",
      "#iscover    bullshit\n",
      "honoured    shitty\n",
      "pioneers    crap\n",
      "#knit       crappy\n",
      "#izons      incompetence\n",
      "#Vers       incompetent\n",
      "#raits      pointless\n",
      "pioneer     retarded\n",
      "#elight     worse\n",
      "enchant     FUCK\n",
      "#Together   idiots\n",
      "reunited    useless\n",
      "powerfully  fuck\n",
      "#joy        worthless\n",
      "Together    garbage\n",
      "pioneering  inco\n",
      "passions    #Fuck\n",
      "timeless    lame\n",
      "lively      shit\n",
      "#inguished  stupid\n",
      "insepar     pathetic\n",
      "#Join       inept\n",
      "renowned    #shit\n",
      "unmatched   piss\n",
      "#Born       asshole\n",
      "#ossom      Worse\n",
      "welcomes    poorly\n",
      "Selected    awful\n",
      "#anqu       stupidity\n",
      "#Discover   ineffective\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(\n",
    "    [*zip(*[top_tokens(pos_vector @ emb1, k=30, only_ascii=True, tokenizer=tokenizer),\n",
    "            top_tokens(neg_vector @ emb1, k=30, only_ascii=True, tokenizer=tokenizer)])],\n",
    "     headers=['POSITIVE', 'NEGATIVE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b63e1491-c1d9-46f9-87e2-c5e8de97b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = 11 # this is the layer we visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83f6a687-7fa9-4e42-82f9-a8f72298d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_K = (model.model.transformer.h[i1].mlp.c_fc.weight.cpu() - old_model.model.transformer.h[i1].mlp.c_fc.weight.cpu()).T\n",
    "diff_V = (model.model.transformer.h[i1].mlp.c_proj.weight.cpu() - old_model.model.transformer.h[i1].mlp.c_proj.weight.cpu())\n",
    "diff_WQ, diff_WK, diff_WV = ((model.model.transformer.h[i1].attn.c_attn.weight.cpu() - \n",
    "                              old_model.model.transformer.h[i1].attn.c_attn.weight.cpu()).T.chunk(3))\n",
    "diff_WO = (model.model.transformer.h[i1].attn.c_proj.weight.cpu() - old_model.model.transformer.h[i1].attn.c_proj.weight.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8977bab0-6c83-4ac3-a842-d6d7c93e3c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_param = diff_WV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c76f6cb-8acd-4753-b0d9-50b59748cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "i2 = np.random.randint(diff_param.shape[0]) # index of vector in the parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8840f5a-3b4e-4b6a-8cc1-06752ec66c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff          -diff\n",
      "------------  -------------\n",
      "incompetence  unforgettable\n",
      "bullshit      beautifully\n",
      "ineffective   wonderfully\n",
      "worthless     vividly\n",
      "bogus         memorable\n",
      "incompetent   thrilling\n",
      "useless       delight\n",
      "retarded      enjoyed\n",
      "retard        timeless\n",
      "shitty        superb\n",
      "worse         wonderful\n",
      "idiots        poignant\n",
      "#Fuck         immensely\n",
      "Worse         exhilar\n",
      "blame         inspiring\n",
      "nonexistent   delightful\n",
      "unus          #love\n",
      "ineligible    lively\n",
      "quotas        vivid\n",
      "inco          fascinating\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(zip(*[top_tokens(diff_param[i2].detach() @ emb1, k=20, only_ascii=True, tokenizer=tokenizer),\n",
    "                top_tokens(-diff_param[i2].detach() @ emb1, k=20, only_ascii=True, tokenizer=tokenizer)]), \n",
    "               headers=[\"diff\", \"-diff\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0c489b-62dd-442c-b7ed-4a2cbdf66fe4",
   "metadata": {},
   "source": [
    "## Model Stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90c6d7c7-d95f-4acd-b4fe-08e4da1bac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_modules(mod1, mod2, subtract_ln=False, only_weight=False):\n",
    "    mod_new = deepcopy(mod1)\n",
    "    with torch.no_grad():\n",
    "        for n, p in mod_new.named_parameters():\n",
    "            if only_weight and not n.endswith('.weight'):\n",
    "                continue\n",
    "            submodule_name = n.rsplit('.', 1)[0] if '.' in n else ''\n",
    "            is_ln = isinstance(mod_new.get_submodule(submodule_name), nn.LayerNorm)\n",
    "            if (not is_ln) or subtract_ln:\n",
    "                p.set_(p.data - mod2.get_parameter(n).data)\n",
    "    return mod_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c78ba6e8-bdd9-4fbf-97a9-d8f4b2b3e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StitchedTransformers(nn.Module):\n",
    "    def __init__(self, old_model, model1, model2, kernel, num_keep_layers, num_transplanted_layers,\n",
    "                subtract=True, **subtract_args):\n",
    "        super().__init__()\n",
    "        self.model2 = deepcopy(model2) \n",
    "        self.model2.transformer.h = nn.ModuleList(self.model2.transformer.h[:num_keep_layers])\n",
    "        self.register_buffer(\"stitching_kernel\", kernel)     \n",
    "        self.model1 = deepcopy(model1)\n",
    "        offset = len(model1.model.transformer.h) - num_transplanted_layers\n",
    "        self.model1.model.transformer.h = nn.ModuleList([\n",
    "        subtract_modules(model1.model.transformer.h[offset + i], \n",
    "                         old_model.model.transformer.h[offset + i], \n",
    "                         **subtract_args) if subtract else model1.model.transformer.h[offset + i]\n",
    "                                                  for i in range(num_transplanted_layers)])\n",
    "        self.model1.model.classifier = (\n",
    "            subtract_modules(model1.model.classifier, old_model.model.classifier, **subtract_args) \n",
    "            if subtract else model1.model.classifier\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_ids, labels):\n",
    "        x = self.model2(input_ids, output_hidden_states=True).hidden_states[-1]\n",
    "        x = x @ self.stitching_kernel\n",
    "        res = self.model1(input_ids=None, inputs_embeds=x, labels=labels)\n",
    "        res = {'loss': res['loss'], 'logits': res['logits']}\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f57515ac-730f-4a8a-b4c9-2d65dcfb33d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended = False\n",
    "kernel = emb_extended2 @ (emb_extended1).pinverse() if extended else emb2 @ (emb1).pinverse()\n",
    "# + .1 * torch.eye(1024, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b724a15a-bf85-4abb-baa1-33c380c13d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtract = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5228ca9-3026-4338-973a-f151ea6b5fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_transplanted_layers = 3\n",
    "num_keep_layers = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5415437-7726-43a3-9823-8af3e9a6ab81",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0c80b60-6c1a-442b-9e64-0aefda4318ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched_model = StitchedTransformers(old_model.cuda(), model1, model2, kernel, \n",
    "                                      num_keep_layers, num_transplanted_layers, subtract=subtract).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "271fa53f-ff22-43e6-a471-945629f46082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 10.434187889099121,\n",
       " 'eval_accuracy': 0.462,\n",
       " 'eval_runtime': 13.4261,\n",
       " 'eval_samples_per_second': 37.241,\n",
       " 'eval_steps_per_second': 37.241}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_stitched = Trainer(stitched_model, args=train_args, train_dataset=imdb_train, eval_dataset=imdb_val, \n",
    "                           compute_metrics=compute_metrics)\n",
    "trainer_stitched.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9fe505-2e9c-4eea-9799-e50ff6a4b5a1",
   "metadata": {},
   "source": [
    "#### Plot All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "febb237a-7c52-4c23-ab44-15909508bf04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `StitchedTransformers.forward` and have been ignored: attention_mask, text. If attention_mask, text are not expected by `StitchedTransformers.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accs = []\n",
    "for num_keep_layers in range(model2.config.n_layer):\n",
    "    stitched_model = StitchedTransformers(old_model.cuda(), model1, model2, kernel, \n",
    "                                          num_keep_layers, num_transplanted_layers, subtract=subtract).cpu()\n",
    "    trainer_stitched = Trainer(stitched_model, args=train_args, train_dataset=imdb_train, eval_dataset=imdb_val, \n",
    "                               compute_metrics=compute_metrics)\n",
    "\n",
    "    accs.append(trainer_stitched.evaluate()['eval_accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
